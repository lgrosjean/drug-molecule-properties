{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\ud83d\udc8a Drug Molecule Properties Forecasting Project to predict drug molecules properties with Deep Learning Quick start Installation This process supposes that you have Anaconda (or Miniconda ) already installed, with git . To install current project locally and access it, first clone the project (do not copy the $ symbol, it only indicates that they are terminal commands): $ git clone https://github.com/lgrosjean/drug-molecule-properties.git $ cd drug-molecule-properties Next, run the following to create Anaconda environment: $ conda create -y --name myenv python = 3 .6 $ conda activate myenv Then, install depencies: ( myenv ) $ pip install -r requirements.txt Finally, build local project into a propre Python package: ( myenv ) $ pip install . -U Check your installation ( myenv ) $ python >>> import smiley >>> print ( smiley . __version__ ) \"0.0.1\" Use with Docker https://github.com/ageron/handson-ml2/tree/master/docker","title":"Home"},{"location":"#drug-molecule-properties-forecasting","text":"Project to predict drug molecules properties with Deep Learning","title":"\ud83d\udc8a Drug Molecule Properties Forecasting"},{"location":"#quick-start","text":"","title":"Quick start"},{"location":"#installation","text":"This process supposes that you have Anaconda (or Miniconda ) already installed, with git . To install current project locally and access it, first clone the project (do not copy the $ symbol, it only indicates that they are terminal commands): $ git clone https://github.com/lgrosjean/drug-molecule-properties.git $ cd drug-molecule-properties Next, run the following to create Anaconda environment: $ conda create -y --name myenv python = 3 .6 $ conda activate myenv Then, install depencies: ( myenv ) $ pip install -r requirements.txt Finally, build local project into a propre Python package: ( myenv ) $ pip install . -U Check your installation ( myenv ) $ python >>> import smiley >>> print ( smiley . __version__ ) \"0.0.1\"","title":"Installation"},{"location":"#use-with-docker","text":"https://github.com/ageron/handson-ml2/tree/master/docker","title":"Use with Docker"},{"location":"dataset/","text":"Module to define Dataset class, and simplify data loading into memory. A unique class is defined here: Dataset . Dataset Class Dataset to load data into memory. __init__ ( self , data_dir = None , load = True ) special Initialize Dataset class. Parameters: Name Type Description Default data_dir Path Location for data directory containing raw csv file. Defaults to None. If None, the default argument will be set as default data_dir for project. None load bool Load dataframe into memoery. Defaults to True. True Source code in smiley/dataset.py def __init__ ( self , data_dir : Path = None , load = True ): \"\"\"Initialize Dataset class. Args: data_dir (Path, optional): Location for data directory containing raw csv file. Defaults to None. If None, the default argument will be set as default data_dir for project. load (bool, optional): Load dataframe into memoery. Defaults to True. \"\"\" self . set_data_dir ( data_dir ) self . path = self . data_dir / f \"dataset_multi.csv\" self . data = None if load : self . load () load ( self ) Load csv located at self.path into class memory. Source code in smiley/dataset.py def load ( self ): \"\"\"Load csv located at `self.path` into class memory.\"\"\" logging . info ( f \"Loading dataset from { self . path } \" ) data = pd . read_csv ( self . path ) self . data = data . copy () self . input_shape = self . data . shape [ 1 ] set_data_dir ( self , data_dir ) Set data_dir attributes. Parameters: Name Type Description Default data_dir str, pathlib.Path The location of the data_dir if not by default. required Source code in smiley/dataset.py def set_data_dir ( self , data_dir ): \"\"\"Set data_dir attributes. Args: data_dir (str, pathlib.Path): The location of the data_dir if not by default. \"\"\" if data_dir is not None : self . data_dir = data_dir else : self . data_dir = Paths ()[ \"data\" ] LoadError An exception raised when the data is not loaded.","title":"Dataset"},{"location":"dataset/#smiley.dataset","text":"Module to define Dataset class, and simplify data loading into memory. A unique class is defined here: Dataset .","title":"smiley.dataset"},{"location":"dataset/#smiley.dataset.Dataset","text":"Class Dataset to load data into memory.","title":"Dataset"},{"location":"dataset/#smiley.dataset.Dataset.__init__","text":"Initialize Dataset class. Parameters: Name Type Description Default data_dir Path Location for data directory containing raw csv file. Defaults to None. If None, the default argument will be set as default data_dir for project. None load bool Load dataframe into memoery. Defaults to True. True Source code in smiley/dataset.py def __init__ ( self , data_dir : Path = None , load = True ): \"\"\"Initialize Dataset class. Args: data_dir (Path, optional): Location for data directory containing raw csv file. Defaults to None. If None, the default argument will be set as default data_dir for project. load (bool, optional): Load dataframe into memoery. Defaults to True. \"\"\" self . set_data_dir ( data_dir ) self . path = self . data_dir / f \"dataset_multi.csv\" self . data = None if load : self . load ()","title":"__init__()"},{"location":"dataset/#smiley.dataset.Dataset.load","text":"Load csv located at self.path into class memory. Source code in smiley/dataset.py def load ( self ): \"\"\"Load csv located at `self.path` into class memory.\"\"\" logging . info ( f \"Loading dataset from { self . path } \" ) data = pd . read_csv ( self . path ) self . data = data . copy () self . input_shape = self . data . shape [ 1 ]","title":"load()"},{"location":"dataset/#smiley.dataset.Dataset.set_data_dir","text":"Set data_dir attributes. Parameters: Name Type Description Default data_dir str, pathlib.Path The location of the data_dir if not by default. required Source code in smiley/dataset.py def set_data_dir ( self , data_dir ): \"\"\"Set data_dir attributes. Args: data_dir (str, pathlib.Path): The location of the data_dir if not by default. \"\"\" if data_dir is not None : self . data_dir = data_dir else : self . data_dir = Paths ()[ \"data\" ]","title":"set_data_dir()"},{"location":"dataset/#smiley.dataset.LoadError","text":"An exception raised when the data is not loaded.","title":"LoadError"},{"location":"installation/","text":"Installation To install more precisely all features, follow the following steps:","title":"Installation"},{"location":"installation/#installation","text":"To install more precisely all features, follow the following steps:","title":"Installation"},{"location":"learner/","text":"This module contains all the Learner to prepare data, prepare model et start training. There is a root learner: BaseTrainer and two childrens: Model1Learner whose aim is to deal with the model 1 problem Model2Learner whose aim is to deal with the model 2 problem BaseTrainer Base trainer to define inputs, hyperparameters and internal methods __init__ ( self , dataset = None , smile_col = 'smiles' , data_dir = None , params = None , ** kwargs ) special Initialization of Base Trainer Parameters: Name Type Description Default dataset Dataset Input dataset for trainer. Defaults to None. If None, Dataset will be generated with default arguments. None smile_col str The column containing the smiles attributes. Defaults to \"smiles\". 'smiles' data_dir str Location of the data for training. Defaults to None. None params dict List of hyperparameters to fit to dataset or model. Defaults to None. None Source code in smiley/learner.py def __init__ ( self , dataset : Dataset = None , smile_col = \"smiles\" , data_dir : str = None , params : dict = None , ** kwargs , ): \"\"\"Initialization of Base Trainer Args: dataset (Dataset, optional): Input dataset for trainer. Defaults to None. If None, Dataset will be generated with default arguments. smile_col (str, optional): The column containing the smiles attributes. Defaults to \"smiles\". data_dir (str, optional): Location of the data for training. Defaults to None. params (dict, optional): List of hyperparameters to fit to dataset or model. Defaults to None. \"\"\" self . X = None self . y = None self . smile_col = smile_col self . model = None self . epochs = 10 self . batch_size = 64 self . verbose = 0 self . shuffle = True self . test_size = 0.2 self . val_size = 0.2 self . class_weight_dict = None self . weighted = True self . metrics = [] self . data_dir = data_dir self . random_state = 54 self . X = None self . y = None self . callbacks = [] self . set_dataset ( dataset ) self . set_params ( params ) self . set_params ( kwargs ) get_params ( self ) Get the hyperparameters of the training Returns: Type Description dict Source code in smiley/learner.py def get_params ( self ) -> dict : \"\"\"Get the hyperparameters of the training Returns: dict: the hyperparamters dictionnary. \"\"\" params = { \"epochs\" : self . epochs , \"batch_size\" : self . batch_size , \"shuffle\" : self . shuffle , \"test_size\" : self . test_size , \"val_size\" : self . val_size , \"weighted\" : self . weighted , } return params is_fitted ( self ) Simple method to check if the attributes X & y exists, and so the dataset has been fitted Returns: Type Description bool Source code in smiley/learner.py def is_fitted ( self ) -> bool : \"\"\"Simple method to check if the attributes X & y exists, and so the dataset has been fitted Returns: bool: The learner is fitted \"\"\" return ( not self . X is None ) and ( not self . y is None ) Model1Learner Model1Learner to use to solve the model 1 problem with converted smiles as input. Model2Learner Model2Learner to use to solve the model 2 problem with the raw smile string as input. OneColLearner Parent class to define more precisely a Learner for a one-column target. Inherits from Base Learner. __init__ ( self , output_col = 'P1' , input_col = None , * args , ** kwargs ) special Initialize One-column learner with inherited attributes. Parameters: Name Type Description Default output_col str The output column for training. Defaults to \"P1\". 'P1' input_col str The input column for training. Defaults to None. None Source code in smiley/learner.py def __init__ ( self , output_col : str = \"P1\" , input_col : str = None , * args , ** kwargs ): \"\"\"Initialize One-column learner with inherited attributes. Args: output_col (str, optional): The output column for training. Defaults to \"P1\". input_col (str, optional): The input column for training. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . output_col = output_col self . input_col = input_col evaluate ( self , function =< function f1_score at 0x7fc9cc1587b8 > , X_test = None , y_test = None , * args , ** kwargs ) Evaluate learner base on sklearen function, on X_test and y_test Parameters: Name Type Description Default function functuin the metric function. From sklearn.metrics . Defaults to f1_score. <function f1_score at 0x7fc9cc1587b8> X_test [pd.DataFrame, np.array] The data on which evaluate learner. Defaults to None. If None , will take the default X_test . None y_test [pd.DataFrame, np.array] The target on which evaluate the model. Defaults to None. If None , will take the default y_test . None Returns: Type Description [float, array of float] the metrics inputs. Source code in smiley/learner.py def evaluate ( self , function = f1_score , X_test = None , y_test = None , * args , ** kwargs ): \"\"\"Evaluate learner base on sklearen function, on `X_test` and `y_test` Args: function (functuin, optional): the metric function. From `sklearn.metrics`. Defaults to f1_score. X_test ([pd.DataFrame, np.array], optional): The data on which evaluate learner. Defaults to None. If `None`, will take the default `X_test`. y_test ([pd.DataFrame, np.array], optional): The target on which evaluate the model. Defaults to None. If `None`, will take the default `y_test`. Returns: [float, array of float]: the metrics inputs. \"\"\" if X_test is not None : self . X_test = X_test if y_test is not None : self . y_test = y_test y_pred = self . model . model . predict ( self . X_test ) y_pred = y_pred > 0.5 return function ( self . y_test , y_pred , * args , ** kwargs ) predict ( self , X_inputs , thresh = 0.5 ) Prediction on X_inputs with predicted class, based on input thresh . Parameters: Name Type Description Default X_inputs [pd.DataFrame, np.array, list] the inputs on which make the prediction required thresh int The threshold between class 0 & 1. Defaults to 0.5. 0.5 Returns: Type Description [type] [description] Source code in smiley/learner.py def predict ( self , X_inputs , thresh : int = 0.5 ): \"\"\"Prediction on `X_inputs` with predicted class, based on input `thresh`. Args: X_inputs ([pd.DataFrame, np.array, list]): the inputs on which make the prediction thresh (int, optional): The threshold between class 0 & 1. Defaults to 0.5. Returns: [type]: [description] \"\"\" pred = self . predict_proba ( X_inputs ) pred = pred > thresh return pred predict_proba ( self , X_inputs ) Prediction on X_inputs with raw outputs (between 0 & 1) Parameters: Name Type Description Default X_inputs [pd.DataFrame, np.array, list] the inputs on which make the prediction required Returns: Type Description [np.array, list] List of predictions Source code in smiley/learner.py def predict_proba ( self , X_inputs ): \"\"\"Prediction on `X_inputs` with raw outputs (between 0 & 1) Args: X_inputs ([pd.DataFrame, np.array, list]): the inputs on which make the prediction Returns: [np.array, list]: List of predictions \"\"\" return self . model . model . predict ( X_inputs ) prepare ( self , weighted = None , random_state = None ) Prepare the Learner and the inputs for learning. Transform the X,y attributes to X_train, y_train, X_test, y_test, X_val, y_val. Also create weighted dictionnary if requested to weigth training if the dataset is imbalanced. Parameters: Name Type Description Default weighted bool [description]. Defaults to None. None random_state int Random state for split and shuffling. Defaults to None. None Source code in smiley/learner.py def prepare ( self , weighted : bool = None , random_state : int = None ): \"\"\"Prepare the Learner and the inputs for learning. Transform the X,y attributes to X_train, y_train, X_test, y_test, X_val, y_val. Also create weighted dictionnary if requested to weigth training if the dataset is imbalanced. Args: weighted (bool, optional): [description]. Defaults to None. random_state (int, optional): Random state for split and shuffling. Defaults to None. \"\"\" self . set_random_state ( random_state = random_state ) self . set_X_y ( self . input_col , self . output_col ) self . X_train , self . X_test , self . y_train , self . y_test = train_test_split ( self . X , self . y , test_size = self . test_size , stratify = self . y , random_state = self . random_state , ) self . X_train , self . X_val , self . y_train , self . y_val = train_test_split ( self . X_train , self . y_train , test_size = self . val_size , stratify = self . y_train , random_state = self . random_state , ) self . validation_data = ( self . X_val , self . y_val ) self . set_class_weight ( weighted = weighted ) train ( self , X_train = None , y_train = None , validation_data = None , early_stopping = None , tqdm = True , ** params ) Base method to train input model. Based on Keras hyperparameters Parameters: Name Type Description Default X_train [pd.DataFrame, np.array] the Keras x input. Defaults to None. If None, the learner will take the attribute X_train fitted in the class. None y_train [pd.DataFrame, np.array] the Keras y input. Defaults to None. If None, the learner will take the attribute y_train fitted in the class. None validation_data [pd.DataFrame, np.array] the Keras validation_data input. Defaults to None. If None, the learner will take the attribute validation_data fitted in the class. None early_stopping int Number of epochs before Early Stopping. Defaults to None. If None, the training will last epochs . None tqdm bool To create tqdm progress bar during training or not. Defaults to True. True Source code in smiley/learner.py def train ( self , X_train = None , y_train = None , validation_data = None , early_stopping : int = None , tqdm = True , ** params , ): \"\"\"Base method to train input model. Based on Keras hyperparameters Args: X_train ([pd.DataFrame, np.array], optional): the Keras `x` input. Defaults to None. If None, the learner will take the attribute `X_train` fitted in the class. y_train ([pd.DataFrame, np.array], optional): the Keras `y` input. Defaults to None. If None, the learner will take the attribute `y_train` fitted in the class. validation_data ([pd.DataFrame, np.array], optional): the Keras `validation_data` input. Defaults to None. If None, the learner will take the attribute `validation_data` fitted in the class. early_stopping (int, optional): Number of epochs before Early Stopping. Defaults to None. If None, the training will last `epochs`. tqdm (bool, optional): To create `tqdm` progress bar during training or not. Defaults to True. \"\"\" if X_train is not None : self . X_train = X_train if y_train is not None : self . y_train = y_train if validation_data is not None : self . validation_data = validation_data if early_stopping : self . early_stopping_ = early_stopping es = keras . callbacks . EarlyStopping ( monitor = \"val_loss\" , patience = self . early_stopping ) self . callbacks . append ( es ) if tqdm : tqdm_nb = TqdmCallback () self . callbacks . append ( tqdm_nb ) self . set_params ( params ) logging . info ( \"Start training\" ) history = self . model . model . fit ( x = self . X_train . values , y = self . y_train , batch_size = self . batch_size , shuffle = self . shuffle , epochs = self . epochs , verbose = self . verbose , validation_data = self . validation_data , class_weight = self . class_weight_dict , callbacks = self . callbacks , ) self . history = history . history","title":"Learner"},{"location":"learner/#smiley.learner","text":"This module contains all the Learner to prepare data, prepare model et start training. There is a root learner: BaseTrainer and two childrens: Model1Learner whose aim is to deal with the model 1 problem Model2Learner whose aim is to deal with the model 2 problem","title":"smiley.learner"},{"location":"learner/#smiley.learner.BaseTrainer","text":"Base trainer to define inputs, hyperparameters and internal methods","title":"BaseTrainer"},{"location":"learner/#smiley.learner.BaseTrainer.__init__","text":"Initialization of Base Trainer Parameters: Name Type Description Default dataset Dataset Input dataset for trainer. Defaults to None. If None, Dataset will be generated with default arguments. None smile_col str The column containing the smiles attributes. Defaults to \"smiles\". 'smiles' data_dir str Location of the data for training. Defaults to None. None params dict List of hyperparameters to fit to dataset or model. Defaults to None. None Source code in smiley/learner.py def __init__ ( self , dataset : Dataset = None , smile_col = \"smiles\" , data_dir : str = None , params : dict = None , ** kwargs , ): \"\"\"Initialization of Base Trainer Args: dataset (Dataset, optional): Input dataset for trainer. Defaults to None. If None, Dataset will be generated with default arguments. smile_col (str, optional): The column containing the smiles attributes. Defaults to \"smiles\". data_dir (str, optional): Location of the data for training. Defaults to None. params (dict, optional): List of hyperparameters to fit to dataset or model. Defaults to None. \"\"\" self . X = None self . y = None self . smile_col = smile_col self . model = None self . epochs = 10 self . batch_size = 64 self . verbose = 0 self . shuffle = True self . test_size = 0.2 self . val_size = 0.2 self . class_weight_dict = None self . weighted = True self . metrics = [] self . data_dir = data_dir self . random_state = 54 self . X = None self . y = None self . callbacks = [] self . set_dataset ( dataset ) self . set_params ( params ) self . set_params ( kwargs )","title":"__init__()"},{"location":"learner/#smiley.learner.BaseTrainer.get_params","text":"Get the hyperparameters of the training Returns: Type Description dict Source code in smiley/learner.py def get_params ( self ) -> dict : \"\"\"Get the hyperparameters of the training Returns: dict: the hyperparamters dictionnary. \"\"\" params = { \"epochs\" : self . epochs , \"batch_size\" : self . batch_size , \"shuffle\" : self . shuffle , \"test_size\" : self . test_size , \"val_size\" : self . val_size , \"weighted\" : self . weighted , } return params","title":"get_params()"},{"location":"learner/#smiley.learner.BaseTrainer.is_fitted","text":"Simple method to check if the attributes X & y exists, and so the dataset has been fitted Returns: Type Description bool Source code in smiley/learner.py def is_fitted ( self ) -> bool : \"\"\"Simple method to check if the attributes X & y exists, and so the dataset has been fitted Returns: bool: The learner is fitted \"\"\" return ( not self . X is None ) and ( not self . y is None )","title":"is_fitted()"},{"location":"learner/#smiley.learner.Model1Learner","text":"Model1Learner to use to solve the model 1 problem with converted smiles as input.","title":"Model1Learner"},{"location":"learner/#smiley.learner.Model2Learner","text":"Model2Learner to use to solve the model 2 problem with the raw smile string as input.","title":"Model2Learner"},{"location":"learner/#smiley.learner.OneColLearner","text":"Parent class to define more precisely a Learner for a one-column target. Inherits from Base Learner.","title":"OneColLearner"},{"location":"learner/#smiley.learner.OneColLearner.__init__","text":"Initialize One-column learner with inherited attributes. Parameters: Name Type Description Default output_col str The output column for training. Defaults to \"P1\". 'P1' input_col str The input column for training. Defaults to None. None Source code in smiley/learner.py def __init__ ( self , output_col : str = \"P1\" , input_col : str = None , * args , ** kwargs ): \"\"\"Initialize One-column learner with inherited attributes. Args: output_col (str, optional): The output column for training. Defaults to \"P1\". input_col (str, optional): The input column for training. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . output_col = output_col self . input_col = input_col","title":"__init__()"},{"location":"learner/#smiley.learner.OneColLearner.evaluate","text":"Evaluate learner base on sklearen function, on X_test and y_test Parameters: Name Type Description Default function functuin the metric function. From sklearn.metrics . Defaults to f1_score. <function f1_score at 0x7fc9cc1587b8> X_test [pd.DataFrame, np.array] The data on which evaluate learner. Defaults to None. If None , will take the default X_test . None y_test [pd.DataFrame, np.array] The target on which evaluate the model. Defaults to None. If None , will take the default y_test . None Returns: Type Description [float, array of float] the metrics inputs. Source code in smiley/learner.py def evaluate ( self , function = f1_score , X_test = None , y_test = None , * args , ** kwargs ): \"\"\"Evaluate learner base on sklearen function, on `X_test` and `y_test` Args: function (functuin, optional): the metric function. From `sklearn.metrics`. Defaults to f1_score. X_test ([pd.DataFrame, np.array], optional): The data on which evaluate learner. Defaults to None. If `None`, will take the default `X_test`. y_test ([pd.DataFrame, np.array], optional): The target on which evaluate the model. Defaults to None. If `None`, will take the default `y_test`. Returns: [float, array of float]: the metrics inputs. \"\"\" if X_test is not None : self . X_test = X_test if y_test is not None : self . y_test = y_test y_pred = self . model . model . predict ( self . X_test ) y_pred = y_pred > 0.5 return function ( self . y_test , y_pred , * args , ** kwargs )","title":"evaluate()"},{"location":"learner/#smiley.learner.OneColLearner.predict","text":"Prediction on X_inputs with predicted class, based on input thresh . Parameters: Name Type Description Default X_inputs [pd.DataFrame, np.array, list] the inputs on which make the prediction required thresh int The threshold between class 0 & 1. Defaults to 0.5. 0.5 Returns: Type Description [type] [description] Source code in smiley/learner.py def predict ( self , X_inputs , thresh : int = 0.5 ): \"\"\"Prediction on `X_inputs` with predicted class, based on input `thresh`. Args: X_inputs ([pd.DataFrame, np.array, list]): the inputs on which make the prediction thresh (int, optional): The threshold between class 0 & 1. Defaults to 0.5. Returns: [type]: [description] \"\"\" pred = self . predict_proba ( X_inputs ) pred = pred > thresh return pred","title":"predict()"},{"location":"learner/#smiley.learner.OneColLearner.predict_proba","text":"Prediction on X_inputs with raw outputs (between 0 & 1) Parameters: Name Type Description Default X_inputs [pd.DataFrame, np.array, list] the inputs on which make the prediction required Returns: Type Description [np.array, list] List of predictions Source code in smiley/learner.py def predict_proba ( self , X_inputs ): \"\"\"Prediction on `X_inputs` with raw outputs (between 0 & 1) Args: X_inputs ([pd.DataFrame, np.array, list]): the inputs on which make the prediction Returns: [np.array, list]: List of predictions \"\"\" return self . model . model . predict ( X_inputs )","title":"predict_proba()"},{"location":"learner/#smiley.learner.OneColLearner.prepare","text":"Prepare the Learner and the inputs for learning. Transform the X,y attributes to X_train, y_train, X_test, y_test, X_val, y_val. Also create weighted dictionnary if requested to weigth training if the dataset is imbalanced. Parameters: Name Type Description Default weighted bool [description]. Defaults to None. None random_state int Random state for split and shuffling. Defaults to None. None Source code in smiley/learner.py def prepare ( self , weighted : bool = None , random_state : int = None ): \"\"\"Prepare the Learner and the inputs for learning. Transform the X,y attributes to X_train, y_train, X_test, y_test, X_val, y_val. Also create weighted dictionnary if requested to weigth training if the dataset is imbalanced. Args: weighted (bool, optional): [description]. Defaults to None. random_state (int, optional): Random state for split and shuffling. Defaults to None. \"\"\" self . set_random_state ( random_state = random_state ) self . set_X_y ( self . input_col , self . output_col ) self . X_train , self . X_test , self . y_train , self . y_test = train_test_split ( self . X , self . y , test_size = self . test_size , stratify = self . y , random_state = self . random_state , ) self . X_train , self . X_val , self . y_train , self . y_val = train_test_split ( self . X_train , self . y_train , test_size = self . val_size , stratify = self . y_train , random_state = self . random_state , ) self . validation_data = ( self . X_val , self . y_val ) self . set_class_weight ( weighted = weighted )","title":"prepare()"},{"location":"learner/#smiley.learner.OneColLearner.train","text":"Base method to train input model. Based on Keras hyperparameters Parameters: Name Type Description Default X_train [pd.DataFrame, np.array] the Keras x input. Defaults to None. If None, the learner will take the attribute X_train fitted in the class. None y_train [pd.DataFrame, np.array] the Keras y input. Defaults to None. If None, the learner will take the attribute y_train fitted in the class. None validation_data [pd.DataFrame, np.array] the Keras validation_data input. Defaults to None. If None, the learner will take the attribute validation_data fitted in the class. None early_stopping int Number of epochs before Early Stopping. Defaults to None. If None, the training will last epochs . None tqdm bool To create tqdm progress bar during training or not. Defaults to True. True Source code in smiley/learner.py def train ( self , X_train = None , y_train = None , validation_data = None , early_stopping : int = None , tqdm = True , ** params , ): \"\"\"Base method to train input model. Based on Keras hyperparameters Args: X_train ([pd.DataFrame, np.array], optional): the Keras `x` input. Defaults to None. If None, the learner will take the attribute `X_train` fitted in the class. y_train ([pd.DataFrame, np.array], optional): the Keras `y` input. Defaults to None. If None, the learner will take the attribute `y_train` fitted in the class. validation_data ([pd.DataFrame, np.array], optional): the Keras `validation_data` input. Defaults to None. If None, the learner will take the attribute `validation_data` fitted in the class. early_stopping (int, optional): Number of epochs before Early Stopping. Defaults to None. If None, the training will last `epochs`. tqdm (bool, optional): To create `tqdm` progress bar during training or not. Defaults to True. \"\"\" if X_train is not None : self . X_train = X_train if y_train is not None : self . y_train = y_train if validation_data is not None : self . validation_data = validation_data if early_stopping : self . early_stopping_ = early_stopping es = keras . callbacks . EarlyStopping ( monitor = \"val_loss\" , patience = self . early_stopping ) self . callbacks . append ( es ) if tqdm : tqdm_nb = TqdmCallback () self . callbacks . append ( tqdm_nb ) self . set_params ( params ) logging . info ( \"Start training\" ) history = self . model . model . fit ( x = self . X_train . values , y = self . y_train , batch_size = self . batch_size , shuffle = self . shuffle , epochs = self . epochs , verbose = self . verbose , validation_data = self . validation_data , class_weight = self . class_weight_dict , callbacks = self . callbacks , ) self . history = history . history","title":"train()"},{"location":"mlflow/","text":"This module contains one only class to deal with MlFlow environment and tracking server: MlFlowTracker . It inherits from base mlflow.tracking.MlflowClient but is augmented with few in-class methods: get_experiment_id : to get the experiment_id based on the experiment_name provided get_best_model : to find the best model depending on the provided metrics for the provided experiment_name gest_best_model_metrics : to find the raw metrics for the best model found with previous arguments get_last_version : to find the number of versions already trained for the provided experiment_name get_new_version : to find the new number of version for the in-progress training. MlFlowTracker Base class to deal with MlFlow environment. __init__ ( self , root_dir = None ) special Initialize class based on root_dir input. This argument is essential to tell the class where to find the mlruns default folder to look for previous experiments. Parameters: Name Type Description Default root_dir str The folder containing the mlruns folder. Defaults to None. If None, set to default root folder. None Source code in smiley/mlflow.py def __init__ ( self , root_dir : str = None ): \"\"\"Initialize class based on `root_dir` input. This argument is essential to tell the class where to find the `mlruns` default folder to look for previous experiments. Args: root_dir (str, optional): The folder containing the `mlruns` folder. Defaults to None. If None, set to default root folder. \"\"\" if root_dir is None : self . root_dir = Paths () . root_dir else : self . root_dir = root_dir os . chdir ( self . root_dir ) super () . __init__ () get_experiment_id ( experiment_name ) staticmethod Get the experiment_id of an experimentation based on its experiment_name Parameters: Name Type Description Default experiment_name str The experiment_name to look for its id required Returns: Type Description str [str]: The experiment_id Source code in smiley/mlflow.py @staticmethod def get_experiment_id ( experiment_name : str ) -> str : \"\"\"Get the experiment_id of an experimentation based on its `experiment_name` Args: experiment_name ([str]): The experiment_name to look for its id Returns: [str]: The experiment_id \"\"\" experiment = mlflow . get_experiment_by_name ( experiment_name ) experiment_id = experiment . experiment_id return experiment_id","title":"Mlflow"},{"location":"mlflow/#smiley.mlflow","text":"This module contains one only class to deal with MlFlow environment and tracking server: MlFlowTracker . It inherits from base mlflow.tracking.MlflowClient but is augmented with few in-class methods: get_experiment_id : to get the experiment_id based on the experiment_name provided get_best_model : to find the best model depending on the provided metrics for the provided experiment_name gest_best_model_metrics : to find the raw metrics for the best model found with previous arguments get_last_version : to find the number of versions already trained for the provided experiment_name get_new_version : to find the new number of version for the in-progress training.","title":"smiley.mlflow"},{"location":"mlflow/#smiley.mlflow.MlFlowTracker","text":"Base class to deal with MlFlow environment.","title":"MlFlowTracker"},{"location":"mlflow/#smiley.mlflow.MlFlowTracker.__init__","text":"Initialize class based on root_dir input. This argument is essential to tell the class where to find the mlruns default folder to look for previous experiments. Parameters: Name Type Description Default root_dir str The folder containing the mlruns folder. Defaults to None. If None, set to default root folder. None Source code in smiley/mlflow.py def __init__ ( self , root_dir : str = None ): \"\"\"Initialize class based on `root_dir` input. This argument is essential to tell the class where to find the `mlruns` default folder to look for previous experiments. Args: root_dir (str, optional): The folder containing the `mlruns` folder. Defaults to None. If None, set to default root folder. \"\"\" if root_dir is None : self . root_dir = Paths () . root_dir else : self . root_dir = root_dir os . chdir ( self . root_dir ) super () . __init__ ()","title":"__init__()"},{"location":"mlflow/#smiley.mlflow.MlFlowTracker.get_experiment_id","text":"Get the experiment_id of an experimentation based on its experiment_name Parameters: Name Type Description Default experiment_name str The experiment_name to look for its id required Returns: Type Description str [str]: The experiment_id Source code in smiley/mlflow.py @staticmethod def get_experiment_id ( experiment_name : str ) -> str : \"\"\"Get the experiment_id of an experimentation based on its `experiment_name` Args: experiment_name ([str]): The experiment_name to look for its id Returns: [str]: The experiment_id \"\"\" experiment = mlflow . get_experiment_by_name ( experiment_name ) experiment_id = experiment . experiment_id return experiment_id","title":"get_experiment_id()"},{"location":"model/","text":"This module contains all the classes defining the Keras model to solve the two problems: Model 1 and Model 2. It defines a base class: BaseModel to instanciate default arguments and methods. The most important parts are defined in the two mains classes: Model1 Model2 BaseModel __init__ ( self , input_shape = None , name = 'model' , optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = [ 'accuracy' ], weighted_metrics = None , model = None ) special Generate base model for learning. Parameters: Name Type Description Default input_shape int input shape for Keras model. None name str Name for Keras model. Defaults to \"model\". 'model' optimizer str Optimizer of Keras model. Defaults to \"adam\". 'adam' loss str Loss for Keras model. Defaults to 'binary_crossentropy'. 'binary_crossentropy' metrics list List of metrics for Keras model training. Defaults to [\"accuracy\"]. ['accuracy'] weighted_metrics list List of weighted metrics to define for Keras model compilation. Defaults to None. None model Model The Keras model. Defaults to None. None Source code in smiley/model.py def __init__ ( self , input_shape : int = None , name : str = \"model\" , optimizer : str = \"adam\" , loss : str = \"binary_crossentropy\" , metrics : list = [ \"accuracy\" ], weighted_metrics : list = None , model : Model = None , ): \"\"\"Generate base model for learning. Args: input_shape (int): input shape for Keras model. name (str, optional): Name for Keras model. Defaults to \"model\". optimizer (str, optional): Optimizer of Keras model. Defaults to \"adam\". loss (str, optional): Loss for Keras model. Defaults to 'binary_crossentropy'. metrics (list, optional): List of metrics for Keras model training. Defaults to [\"accuracy\"]. weighted_metrics (list, optional): List of weighted metrics to define for Keras model compilation. Defaults to None. model (Model, optional): The Keras model. Defaults to None. \"\"\" self . input_shape = input_shape self . name = name self . optimizer = optimizer self . loss = loss self . metrics = metrics self . weighted_metrics = weighted_metrics self . model = model self . create () self . compile () Model1 Model class which defines the core Keras model for the problem 1. The model is the following: inputs = Input ( shape = ( self . input_shape ,)) norm = Normalization ()( inputs ) dense_1 = Dense ( 32 , activation = \"relu\" )( norm ) relu_1 = ReLU ()( dense_1 ) dense_2 = Dense ( 32 , activation = \"relu\" )( relu_1 ) outputs = Dense ( 1 , activation = \"sigmoid\" )( dense_2 ) self . model = Model ( inputs = inputs , outputs = outputs , name = self . name ) Model2 Model class which defines the core Keras model for the problem 2. The model is the following: inputs = Input ( shape = ( 1 ,), dtype = tf . string , name = \"inputs\" ) x = TextVectorization ( max_tokens = 5000 , ngrams = self . ngrams , output_sequence_length = self . vocab_size , name = \"text_vectorization\" , )( inputs ) x = Embedding ( input_dim = self . vocab_size , output_dim = self . emb_output_dim , input_length = self . emb_input_length , name = \"embedding\" , )( x ) x = Dropout ( 0.3 , name = \"dropout_1\" )( x ) x = Conv1D ( filters = 32 , kernel_size = 5 , activation = \"relu\" , name = \"conv1d\" )( x ) x = MaxPooling1D ( pool_size = 2 , name = \"max_pooling\" )( x ) x = LSTM ( self . lstm_cell , name = \"lstm\" )( x ) output = Dense ( 1 , activation = \"sigmoid\" , name = \"output_P1\" )( x ) self . model = Model ( inputs = inputs , outputs = output ) ModelCreationError An exception raised when a model is not created.","title":"Model"},{"location":"model/#smiley.model","text":"This module contains all the classes defining the Keras model to solve the two problems: Model 1 and Model 2. It defines a base class: BaseModel to instanciate default arguments and methods. The most important parts are defined in the two mains classes: Model1 Model2","title":"smiley.model"},{"location":"model/#smiley.model.BaseModel","text":"","title":"BaseModel"},{"location":"model/#smiley.model.BaseModel.__init__","text":"Generate base model for learning. Parameters: Name Type Description Default input_shape int input shape for Keras model. None name str Name for Keras model. Defaults to \"model\". 'model' optimizer str Optimizer of Keras model. Defaults to \"adam\". 'adam' loss str Loss for Keras model. Defaults to 'binary_crossentropy'. 'binary_crossentropy' metrics list List of metrics for Keras model training. Defaults to [\"accuracy\"]. ['accuracy'] weighted_metrics list List of weighted metrics to define for Keras model compilation. Defaults to None. None model Model The Keras model. Defaults to None. None Source code in smiley/model.py def __init__ ( self , input_shape : int = None , name : str = \"model\" , optimizer : str = \"adam\" , loss : str = \"binary_crossentropy\" , metrics : list = [ \"accuracy\" ], weighted_metrics : list = None , model : Model = None , ): \"\"\"Generate base model for learning. Args: input_shape (int): input shape for Keras model. name (str, optional): Name for Keras model. Defaults to \"model\". optimizer (str, optional): Optimizer of Keras model. Defaults to \"adam\". loss (str, optional): Loss for Keras model. Defaults to 'binary_crossentropy'. metrics (list, optional): List of metrics for Keras model training. Defaults to [\"accuracy\"]. weighted_metrics (list, optional): List of weighted metrics to define for Keras model compilation. Defaults to None. model (Model, optional): The Keras model. Defaults to None. \"\"\" self . input_shape = input_shape self . name = name self . optimizer = optimizer self . loss = loss self . metrics = metrics self . weighted_metrics = weighted_metrics self . model = model self . create () self . compile ()","title":"__init__()"},{"location":"model/#smiley.model.Model1","text":"Model class which defines the core Keras model for the problem 1. The model is the following: inputs = Input ( shape = ( self . input_shape ,)) norm = Normalization ()( inputs ) dense_1 = Dense ( 32 , activation = \"relu\" )( norm ) relu_1 = ReLU ()( dense_1 ) dense_2 = Dense ( 32 , activation = \"relu\" )( relu_1 ) outputs = Dense ( 1 , activation = \"sigmoid\" )( dense_2 ) self . model = Model ( inputs = inputs , outputs = outputs , name = self . name )","title":"Model1"},{"location":"model/#smiley.model.Model2","text":"Model class which defines the core Keras model for the problem 2. The model is the following: inputs = Input ( shape = ( 1 ,), dtype = tf . string , name = \"inputs\" ) x = TextVectorization ( max_tokens = 5000 , ngrams = self . ngrams , output_sequence_length = self . vocab_size , name = \"text_vectorization\" , )( inputs ) x = Embedding ( input_dim = self . vocab_size , output_dim = self . emb_output_dim , input_length = self . emb_input_length , name = \"embedding\" , )( x ) x = Dropout ( 0.3 , name = \"dropout_1\" )( x ) x = Conv1D ( filters = 32 , kernel_size = 5 , activation = \"relu\" , name = \"conv1d\" )( x ) x = MaxPooling1D ( pool_size = 2 , name = \"max_pooling\" )( x ) x = LSTM ( self . lstm_cell , name = \"lstm\" )( x ) output = Dense ( 1 , activation = \"sigmoid\" , name = \"output_P1\" )( x ) self . model = Model ( inputs = inputs , outputs = output )","title":"Model2"},{"location":"model/#smiley.model.ModelCreationError","text":"An exception raised when a model is not created.","title":"ModelCreationError"},{"location":"train/","text":"Core model to train our models. Two models can be trained : model1 : will train the Model1Learner model2 : will train the Model2Learner It also creates Mlflow tracking experience to quicker check if performance has improved or not. All the tracking experiments can be found through: $ mlflow ui --port 54180 It will also convert Keras model into TfSavedModel to be integrated in Tensorflow Serving services, to request predictions. By defaults, each model will be saved in the corresponding folder in the model/models folder. In particular, the model2 model has to be transform in a specific TFModel in order to understand raw string with shape=1 as inputs during serving. MODEL_DICT Root variable to map input model name to the corresponding Learner: model1 : Model1Learner model2 : Model2Learner TFModel Specific class to transform tf.keras.Model into tf.Module to understand raw string input during prediction. Its two attributes will be integrated in the saving, especially the prediction which will be integrated in the signatures of the SavedModel. prediction ( self , smile ) The base prediction model to define input_signature. Will return a dictionnary as prediction in the format: {\"prediction\": prediction} Parameters: Name Type Description Default smile str The input raw smile as string. required Returns: Type Description dict A dict for the prediction containing only the key \"prediction\" Source code in smiley/train.py @tf . function ( input_signature = [ tf . TensorSpec ( shape = ( 1 ,), dtype = tf . string )]) def prediction ( self , smile : str ): \"\"\"The base prediction model to define input_signature. Will return a dictionnary as prediction in the format: `{\"prediction\": prediction}` Args: smile (str): The input raw smile as string. Returns: dict: A dict for the prediction containing only the key \"prediction\" \"\"\" return { \"prediction\" : self . model ( smile ), } train ( model , experiment_name = None , best_metric = 'val_accuracy' , ** kwargs ) Base method to train a model. Will train the model input based on MODEL_DICT correspondance, and define the experiment_name in MlFlow tracking. Parameters: Name Type Description Default model str the model to train. Only two choices: model1 or model2 . required experiment_name str The experiment name to define in MlFlow tracking server. Defaults to None. If None, will be define with model value. None best_metric str The metrics on which performing evaluation of the model, and to check if performance has improved since best last model. Defaults to \"val_accuracy\". 'val_accuracy' Source code in smiley/train.py def train ( model : str , experiment_name : str = None , best_metric = \"val_accuracy\" , ** kwargs ): \"\"\"Base method to train a model. Will train the model input based on `MODEL_DICT` correspondance, and define the `experiment_name` in MlFlow tracking. Args: model (str): the model to train. Only two choices: `model1` or `model2`. experiment_name (str, optional): The experiment name to define in MlFlow tracking server. Defaults to None. If None, will be define with `model` value. best_metric (str, optional): The metrics on which performing evaluation of the model, and to check if performance has improved since best last model. Defaults to \"val_accuracy\". \"\"\" _check_input ( model ) if experiment_name is None : experiment_name = model owd = os . getcwd () root_dir = Paths () . root_dir os . chdir ( root_dir ) mlflow . set_experiment ( experiment_name ) tracker = MlFlowTracker () timestamp = time . strftime ( \"%Y%m %d %H%M\" ) run_name = f \" { experiment_name } _ { timestamp } \" learner = MODEL_DICT . get ( model )() print ( learner . name ) version = tracker . get_new_version ( experiment_name ) logging . info ( version ) with mlflow . start_run ( run_name = run_name ): run_uuid = mlflow . active_run () . info . run_uuid logging . info ( f \"MLflow Run ID: { run_uuid } \" ) learner . train ( ** kwargs ) # Get training params params = learner . get_params () # Log parameters mlflow . log_params ( params ) # calculate metrics metrics = {} for metric in learner . metrics : metrics [ metric ] = learner . history [ metric ][ - 1 ] metrics [ f \"val_ { metric } \" ] = learner . history [ f \"val_ { metric } \" ][ - 1 ] metrics [ \"loss\" ] = learner . history [ \"loss\" ][ - 1 ] metrics [ \"val_loss\" ] = learner . history [ \"val_loss\" ][ - 1 ] final_metric = metrics . get ( best_metric ) # log metrics mlflow . log_metrics ( metrics ) # log model model_name = learner . model . name X_train = learner . X_train y_pred = learner . predict ( X_train ) signature = infer_signature ( X_train , y_pred ) mlflow . keras . log_model ( learner . model . model , model_name , signature = signature , save_format = \"tf\" ) models_path = Paths () . model / \"models\" if not models_path . exists (): models_path . mkdir () final_metric_best = tracker . get_best_model_metric ( experiment_name , metric = best_metric ) if final_metric >= final_metric_best : logging . info ( \"Best model found. Saving to model dir to use with Tensorflow Serving\" ) model_path = os . path . join ( str ( models_path ), model ) if not os . path . exists ( model_path ): os . mkdir ( model_path ) logging . info ( f \"Folder \" ) if model == \"model2\" : tfmodel = TFModel ( learner . model . model ) tf . saved_model . save ( tfmodel . model , os . path . join ( model_path , \"0\" ), signatures = { \"serving_default\" : tfmodel . prediction }, ) print ( tfmodel ) else : learner . model . model . save ( os . path . join ( model_path , \"0\" )) logging . info ( f \"Model exported at { model_path } .\" ) else : logging . info ( f \"Model logged but best performance not improved for experiment { experiment_name } (current version: { version } ).\" ) os . chdir ( owd )","title":"Train"},{"location":"train/#smiley.train","text":"Core model to train our models. Two models can be trained : model1 : will train the Model1Learner model2 : will train the Model2Learner It also creates Mlflow tracking experience to quicker check if performance has improved or not. All the tracking experiments can be found through: $ mlflow ui --port 54180 It will also convert Keras model into TfSavedModel to be integrated in Tensorflow Serving services, to request predictions. By defaults, each model will be saved in the corresponding folder in the model/models folder. In particular, the model2 model has to be transform in a specific TFModel in order to understand raw string with shape=1 as inputs during serving.","title":"smiley.train"},{"location":"train/#smiley.train.MODEL_DICT","text":"Root variable to map input model name to the corresponding Learner: model1 : Model1Learner model2 : Model2Learner","title":"MODEL_DICT"},{"location":"train/#smiley.train.TFModel","text":"Specific class to transform tf.keras.Model into tf.Module to understand raw string input during prediction. Its two attributes will be integrated in the saving, especially the prediction which will be integrated in the signatures of the SavedModel.","title":"TFModel"},{"location":"train/#smiley.train.TFModel.prediction","text":"The base prediction model to define input_signature. Will return a dictionnary as prediction in the format: {\"prediction\": prediction} Parameters: Name Type Description Default smile str The input raw smile as string. required Returns: Type Description dict A dict for the prediction containing only the key \"prediction\" Source code in smiley/train.py @tf . function ( input_signature = [ tf . TensorSpec ( shape = ( 1 ,), dtype = tf . string )]) def prediction ( self , smile : str ): \"\"\"The base prediction model to define input_signature. Will return a dictionnary as prediction in the format: `{\"prediction\": prediction}` Args: smile (str): The input raw smile as string. Returns: dict: A dict for the prediction containing only the key \"prediction\" \"\"\" return { \"prediction\" : self . model ( smile ), }","title":"prediction()"},{"location":"train/#smiley.train.train","text":"Base method to train a model. Will train the model input based on MODEL_DICT correspondance, and define the experiment_name in MlFlow tracking. Parameters: Name Type Description Default model str the model to train. Only two choices: model1 or model2 . required experiment_name str The experiment name to define in MlFlow tracking server. Defaults to None. If None, will be define with model value. None best_metric str The metrics on which performing evaluation of the model, and to check if performance has improved since best last model. Defaults to \"val_accuracy\". 'val_accuracy' Source code in smiley/train.py def train ( model : str , experiment_name : str = None , best_metric = \"val_accuracy\" , ** kwargs ): \"\"\"Base method to train a model. Will train the model input based on `MODEL_DICT` correspondance, and define the `experiment_name` in MlFlow tracking. Args: model (str): the model to train. Only two choices: `model1` or `model2`. experiment_name (str, optional): The experiment name to define in MlFlow tracking server. Defaults to None. If None, will be define with `model` value. best_metric (str, optional): The metrics on which performing evaluation of the model, and to check if performance has improved since best last model. Defaults to \"val_accuracy\". \"\"\" _check_input ( model ) if experiment_name is None : experiment_name = model owd = os . getcwd () root_dir = Paths () . root_dir os . chdir ( root_dir ) mlflow . set_experiment ( experiment_name ) tracker = MlFlowTracker () timestamp = time . strftime ( \"%Y%m %d %H%M\" ) run_name = f \" { experiment_name } _ { timestamp } \" learner = MODEL_DICT . get ( model )() print ( learner . name ) version = tracker . get_new_version ( experiment_name ) logging . info ( version ) with mlflow . start_run ( run_name = run_name ): run_uuid = mlflow . active_run () . info . run_uuid logging . info ( f \"MLflow Run ID: { run_uuid } \" ) learner . train ( ** kwargs ) # Get training params params = learner . get_params () # Log parameters mlflow . log_params ( params ) # calculate metrics metrics = {} for metric in learner . metrics : metrics [ metric ] = learner . history [ metric ][ - 1 ] metrics [ f \"val_ { metric } \" ] = learner . history [ f \"val_ { metric } \" ][ - 1 ] metrics [ \"loss\" ] = learner . history [ \"loss\" ][ - 1 ] metrics [ \"val_loss\" ] = learner . history [ \"val_loss\" ][ - 1 ] final_metric = metrics . get ( best_metric ) # log metrics mlflow . log_metrics ( metrics ) # log model model_name = learner . model . name X_train = learner . X_train y_pred = learner . predict ( X_train ) signature = infer_signature ( X_train , y_pred ) mlflow . keras . log_model ( learner . model . model , model_name , signature = signature , save_format = \"tf\" ) models_path = Paths () . model / \"models\" if not models_path . exists (): models_path . mkdir () final_metric_best = tracker . get_best_model_metric ( experiment_name , metric = best_metric ) if final_metric >= final_metric_best : logging . info ( \"Best model found. Saving to model dir to use with Tensorflow Serving\" ) model_path = os . path . join ( str ( models_path ), model ) if not os . path . exists ( model_path ): os . mkdir ( model_path ) logging . info ( f \"Folder \" ) if model == \"model2\" : tfmodel = TFModel ( learner . model . model ) tf . saved_model . save ( tfmodel . model , os . path . join ( model_path , \"0\" ), signatures = { \"serving_default\" : tfmodel . prediction }, ) print ( tfmodel ) else : learner . model . model . save ( os . path . join ( model_path , \"0\" )) logging . info ( f \"Model exported at { model_path } .\" ) else : logging . info ( f \"Model logged but best performance not improved for experiment { experiment_name } (current version: { version } ).\" ) os . chdir ( owd )","title":"train()"},{"location":"training/","text":"Train To train your models, follow the following steps","title":"Train your models"},{"location":"training/#train","text":"To train your models, follow the following steps","title":"Train"},{"location":"utils/","text":"InputError Raised when the input model required is not existing LoadError Raised when the data is not loaded Paths Base object to centralize all paths and directory for projets __init__ ( self , src_dirname = 'smiley' , data_dirname = 'data' , app_dirname = 'app' , model_dirname = 'model' , mlruns_dirname = 'mlruns' , force = False ) special Initialize Paths object for project Parameters: Name Type Description Default src_dirname str Name of src folder containing scripts. Defaults to \"smiley\". 'smiley' data_dirname str Name of data folder, containing all data for training. Defaults to \"data\". 'data' app_dirname str Name of the app folder containing all the requirements for Flask application. Defaults to \"app\". 'app' model_dirname str Name of the model folder containing all resources to deploy Tensorflow Serving models. Defaults to \"model\". 'model' mlruns_dirname str Name of the MlFlow runs directory to save trainings. Defaults to \"mlruns\". 'mlruns' force bool [description]. Defaults to False. False Source code in smiley/utils.py def __init__ ( self , src_dirname = \"smiley\" , data_dirname = \"data\" , app_dirname = \"app\" , model_dirname = \"model\" , mlruns_dirname = \"mlruns\" , force = False , ): \"\"\"Initialize Paths object for project Args: src_dirname (str, optional): Name of `src`folder containing scripts. Defaults to \"smiley\". data_dirname (str, optional): Name of data folder, containing all data for training. Defaults to \"data\". app_dirname (str, optional): Name of the `app` folder containing all the requirements for Flask application. Defaults to \"app\". model_dirname (str, optional): Name of the `model` folder containing all resources to deploy Tensorflow Serving models. Defaults to \"model\". mlruns_dirname (str, optional): Name of the MlFlow runs directory to save trainings. Defaults to \"mlruns\". force (bool, optional): [description]. Defaults to False. \"\"\" self . root_dir = Path ( abspath ( __file__ )) . parents [ 1 ] self . src_dirname = src_dirname self . data_dirname = data_dirname self . app_dirname = app_dirname self . model_dirname = model_dirname self . mlruns_dirname = mlruns_dirname self . set_list_dir () if not self . data_dirname in self . list_dir : self . root_dir = self . root_dir . parents [ 0 ] self . set_list_dir () self . d = { \"src\" : self . root_dir / self . src_dirname , \"data\" : self . root_dir / self . data_dirname , \"model\" : self . root_dir / self . model_dirname , # 'mlruns': self.root_dir / self.mlruns_dirname } self . dirs = list ( self . d . keys ()) get_list_dir ( self ) Return list of directories in the project folder. Returns: Type Description list Source code in smiley/utils.py def get_list_dir ( self ) -> list : \"\"\"Return list of directories in the project folder. Returns: list: list of subdirectories. \"\"\" return self . list_dir set_list_dir ( self ) Set the list of directories in the Project folder. Source code in smiley/utils.py def set_list_dir ( self ): \"\"\"Set the list of directories in the Project folder.\"\"\" self . list_dir = [ p . name for p in self . root_dir . iterdir ()] smile2bytes ( smile ) Convert a smile string into a bytes-vector list. Parameters: Name Type Description Default smile str The string representation of a smile required Returns: Type Description list Source code in smiley/utils.py def smile2bytes ( smile : str ) -> list : \"\"\"Convert a smile string into a bytes-vector list. Args: smile (str): The string representation of a smile Returns: list: List of bytes representing the smile \"\"\" bit_vect = fingerprint_features ( smile ) return list ( bit_vect )","title":"Utils"},{"location":"utils/#smiley.utils","text":"","title":"smiley.utils"},{"location":"utils/#smiley.utils.InputError","text":"Raised when the input model required is not existing","title":"InputError"},{"location":"utils/#smiley.utils.LoadError","text":"Raised when the data is not loaded","title":"LoadError"},{"location":"utils/#smiley.utils.Paths","text":"Base object to centralize all paths and directory for projets","title":"Paths"},{"location":"utils/#smiley.utils.Paths.__init__","text":"Initialize Paths object for project Parameters: Name Type Description Default src_dirname str Name of src folder containing scripts. Defaults to \"smiley\". 'smiley' data_dirname str Name of data folder, containing all data for training. Defaults to \"data\". 'data' app_dirname str Name of the app folder containing all the requirements for Flask application. Defaults to \"app\". 'app' model_dirname str Name of the model folder containing all resources to deploy Tensorflow Serving models. Defaults to \"model\". 'model' mlruns_dirname str Name of the MlFlow runs directory to save trainings. Defaults to \"mlruns\". 'mlruns' force bool [description]. Defaults to False. False Source code in smiley/utils.py def __init__ ( self , src_dirname = \"smiley\" , data_dirname = \"data\" , app_dirname = \"app\" , model_dirname = \"model\" , mlruns_dirname = \"mlruns\" , force = False , ): \"\"\"Initialize Paths object for project Args: src_dirname (str, optional): Name of `src`folder containing scripts. Defaults to \"smiley\". data_dirname (str, optional): Name of data folder, containing all data for training. Defaults to \"data\". app_dirname (str, optional): Name of the `app` folder containing all the requirements for Flask application. Defaults to \"app\". model_dirname (str, optional): Name of the `model` folder containing all resources to deploy Tensorflow Serving models. Defaults to \"model\". mlruns_dirname (str, optional): Name of the MlFlow runs directory to save trainings. Defaults to \"mlruns\". force (bool, optional): [description]. Defaults to False. \"\"\" self . root_dir = Path ( abspath ( __file__ )) . parents [ 1 ] self . src_dirname = src_dirname self . data_dirname = data_dirname self . app_dirname = app_dirname self . model_dirname = model_dirname self . mlruns_dirname = mlruns_dirname self . set_list_dir () if not self . data_dirname in self . list_dir : self . root_dir = self . root_dir . parents [ 0 ] self . set_list_dir () self . d = { \"src\" : self . root_dir / self . src_dirname , \"data\" : self . root_dir / self . data_dirname , \"model\" : self . root_dir / self . model_dirname , # 'mlruns': self.root_dir / self.mlruns_dirname } self . dirs = list ( self . d . keys ())","title":"__init__()"},{"location":"utils/#smiley.utils.Paths.get_list_dir","text":"Return list of directories in the project folder. Returns: Type Description list Source code in smiley/utils.py def get_list_dir ( self ) -> list : \"\"\"Return list of directories in the project folder. Returns: list: list of subdirectories. \"\"\" return self . list_dir","title":"get_list_dir()"},{"location":"utils/#smiley.utils.Paths.set_list_dir","text":"Set the list of directories in the Project folder. Source code in smiley/utils.py def set_list_dir ( self ): \"\"\"Set the list of directories in the Project folder.\"\"\" self . list_dir = [ p . name for p in self . root_dir . iterdir ()]","title":"set_list_dir()"},{"location":"utils/#smiley.utils.smile2bytes","text":"Convert a smile string into a bytes-vector list. Parameters: Name Type Description Default smile str The string representation of a smile required Returns: Type Description list Source code in smiley/utils.py def smile2bytes ( smile : str ) -> list : \"\"\"Convert a smile string into a bytes-vector list. Args: smile (str): The string representation of a smile Returns: list: List of bytes representing the smile \"\"\" bit_vect = fingerprint_features ( smile ) return list ( bit_vect )","title":"smile2bytes()"}]}